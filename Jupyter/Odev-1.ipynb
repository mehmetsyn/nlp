{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414734c9-1c86-458d-9ca6-e8639b856633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haber Başlığı Çoğaltma Tespiti - Ödev 1\n",
      "==================================================\n",
      "'ekonomi' konusu için veri toplama...\n",
      "'siyaset' konusu için veri toplama...\n",
      "'spor' konusu için veri toplama...\n",
      "'teknoloji' konusu için veri toplama...\n",
      "'sağlık' konusu için veri toplama...\n",
      "'eğitim' konusu için veri toplama...\n",
      "'çevre' konusu için veri toplama...\n",
      "'kültür' konusu için veri toplama...\n",
      "Toplam 800 haber başlığı toplandı\n",
      "\n",
      "Veri Seti Analizi:\n",
      "- Toplam kayıt: 800\n",
      "- Benzersiz başlık: 694\n",
      "- Kaynak sayısı: 19\n",
      "2025-06-17 17:13:59,605 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 6.267392635345459\n",
      "\n",
      "Zemberek başarıyla yüklendi\n",
      "\n",
      "Metin ön işleme başlıyor...\n",
      "Temizleme sonrası kayıt sayısı: 800\n",
      "Temizlenmiş veri setleri kaydedildi:\n",
      "- lemmatized.csv\n",
      "- stemmed.csv\n",
      "\n",
      "TF-IDF modelleri oluşturuluyor...\n",
      "TF-IDF modelleri kaydedildi\n",
      "\n",
      "Word2Vec modelleri oluşturuluyor...\n",
      "2025-06-17 17:14:10,225 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,225 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,230 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,231 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,233 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.233749', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,233 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.233749', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,242 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:10,242 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:10,242 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:10.242218', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,248 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 100 dimensions: 1426100 bytes\n",
      "\n",
      "2025-06-17 17:14:10,248 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:10,248 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:10.248634', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,248 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:10.248634', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,265 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 756807 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,265 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4378 effective words) took 0.0s, 951553 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,282 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4400 effective words) took 0.0s, 767339 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,282 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4382 effective words) took 0.0s, 909582 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,298 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4366 effective words) took 0.0s, 758803 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,314 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4376 effective words) took 0.0s, 925217 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,315 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4362 effective words) took 0.0s, 932689 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,332 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4355 effective words) took 0.0s, 852434 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,332 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4377 effective words) took 0.0s, 870871 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4390 effective words) took 0.0s, 811535 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43739 effective words) took 0.1s, 452742 effective words/s', 'datetime': '2025-06-17T17:14:10.348805', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:10.348805', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_1.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:10.348805', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_1.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_1.model\n",
      "2025-06-17 17:14:10,348 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,348 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,365 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.365492', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,365 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.365492', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,365 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:10,365 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:10,365 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:10.365492', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,382 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 100 dimensions: 1426100 bytes\n",
      "\n",
      "2025-06-17 17:14:10,382 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:10,382 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:10.382205', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,382 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:10.382205', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,382 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 852309 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,398 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4369 effective words) took 0.0s, 780625 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,414 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4381 effective words) took 0.0s, 896900 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,415 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4378 effective words) took 0.0s, 775265 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,432 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4384 effective words) took 0.0s, 1186789 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,432 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4391 effective words) took 0.0s, 895154 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,451 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4380 effective words) took 0.0s, 695205 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,465 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4383 effective words) took 0.0s, 857579 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,465 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4356 effective words) took 0.0s, 867435 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4413 effective words) took 0.0s, 683561 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43788 effective words) took 0.1s, 428354 effective words/s', 'datetime': '2025-06-17T17:14:10.487043', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:10.487043', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_2.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:10.487043', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_2.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_2.model\n",
      "2025-06-17 17:14:10,487 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,487 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,497 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,498 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,499 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.499022', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,499 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.499022', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,499 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:10,499 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:10,499 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:10.499022', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,515 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 200 dimensions: 2303700 bytes\n",
      "\n",
      "2025-06-17 17:14:10,515 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:10,515 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:10.515711', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,515 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:10.515711', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,532 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 700087 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,553 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4378 effective words) took 0.0s, 313637 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,565 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4400 effective words) took 0.0s, 570547 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,586 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4382 effective words) took 0.0s, 533109 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,598 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4366 effective words) took 0.0s, 659836 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,598 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4376 effective words) took 0.0s, 749431 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,615 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4362 effective words) took 0.0s, 666422 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,632 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4355 effective words) took 0.0s, 714837 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,632 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4377 effective words) took 0.0s, 765424 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,649 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4390 effective words) took 0.0s, 679693 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,649 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43739 effective words) took 0.1s, 320042 effective words/s', 'datetime': '2025-06-17T17:14:10.649216', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,649 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:10.649216', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:10,649 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_3.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:10.649216', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:10,649 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:10,665 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_3.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_3.model\n",
      "2025-06-17 17:14:10,665 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,665 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,665 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,665 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,673 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.673872', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,673 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.673872', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,679 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:10,679 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:10,679 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:10.679663', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,682 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 200 dimensions: 2303700 bytes\n",
      "\n",
      "2025-06-17 17:14:10,682 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:10,682 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:10.682668', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,682 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:10.682668', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,699 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 697619 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,699 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4369 effective words) took 0.0s, 761641 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,724 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4381 effective words) took 0.0s, 625768 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,736 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4378 effective words) took 0.0s, 504506 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,748 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4384 effective words) took 0.0s, 772715 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,749 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4391 effective words) took 0.0s, 664166 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,765 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4380 effective words) took 0.0s, 724854 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,782 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4383 effective words) took 0.0s, 728763 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,782 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4356 effective words) took 0.0s, 697663 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,799 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4413 effective words) took 0.0s, 761729 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,799 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43788 effective words) took 0.1s, 395402 effective words/s', 'datetime': '2025-06-17T17:14:10.799131', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,799 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:10.799131', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:10,799 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_4.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:10.799131', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:10,799 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:10,808 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_4.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_4.model\n",
      "2025-06-17 17:14:10,808 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,808 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,808 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,808 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,815 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.815881', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,815 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.815881', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,815 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:10,815 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:10,815 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:10.815881', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,832 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 100 dimensions: 1426100 bytes\n",
      "\n",
      "2025-06-17 17:14:10,832 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:10,832 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:10.832525', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,832 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:10.832525', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,849 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 413437 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,865 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4378 effective words) took 0.0s, 421748 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,882 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4400 effective words) took 0.0s, 381676 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,898 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4382 effective words) took 0.0s, 400974 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,905 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4366 effective words) took 0.0s, 448245 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,922 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4376 effective words) took 0.0s, 429871 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,938 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4362 effective words) took 0.0s, 420628 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,956 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4355 effective words) took 0.0s, 398452 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,969 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4377 effective words) took 0.0s, 374669 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,988 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4390 effective words) took 0.0s, 338325 effective words/s\n",
      "\n",
      "2025-06-17 17:14:10,988 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43739 effective words) took 0.2s, 280762 effective words/s', 'datetime': '2025-06-17T17:14:10.988585', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:10,988 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:10.988585', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:10,988 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_5.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:10.988585', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:10,988 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:10,998 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_5.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_5.model\n",
      "2025-06-17 17:14:10,999 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:10.999525', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:10.999525', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:10,999 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:11,015 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,016 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:11.016735', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,022 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 100 dimensions: 1426100 bytes\n",
      "\n",
      "2025-06-17 17:14:11,022 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,022 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.022738', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,028 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.028530', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,033 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 341120 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,055 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4369 effective words) took 0.0s, 365895 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,066 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4381 effective words) took 0.0s, 327524 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,088 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4378 effective words) took 0.0s, 356057 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,105 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4384 effective words) took 0.0s, 347556 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,128 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4391 effective words) took 0.0s, 358672 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,139 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4380 effective words) took 0.0s, 351232 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,155 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4383 effective words) took 0.0s, 354560 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,172 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4356 effective words) took 0.0s, 346989 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,199 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4413 effective words) took 0.0s, 341468 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,200 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43788 effective words) took 0.2s, 255794 effective words/s', 'datetime': '2025-06-17T17:14:11.200295', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,200 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:11.200295', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:11,201 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_6.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:11.201315', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:11,202 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_6.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_6.model\n",
      "2025-06-17 17:14:11,206 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:11.206165', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,206 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:11.206165', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,220 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:11,222 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,222 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:11.222548', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,228 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 200 dimensions: 2303700 bytes\n",
      "\n",
      "2025-06-17 17:14:11,232 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,234 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.234858', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,234 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.234858', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,252 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 340829 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,270 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4378 effective words) took 0.0s, 357446 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,286 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4400 effective words) took 0.0s, 371073 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,303 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4382 effective words) took 0.0s, 346666 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,321 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4366 effective words) took 0.0s, 321296 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,337 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4376 effective words) took 0.0s, 363633 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,354 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4362 effective words) took 0.0s, 357608 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,371 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4355 effective words) took 0.0s, 362506 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,387 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4377 effective words) took 0.0s, 370170 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,404 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4390 effective words) took 0.0s, 353255 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,405 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43739 effective words) took 0.2s, 258149 effective words/s', 'datetime': '2025-06-17T17:14:11.405596', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,406 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:11.406490', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:11,406 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_7.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:11.406490', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:11,406 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:11,413 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_7.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_7.model\n",
      "2025-06-17 17:14:11,416 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:11,417 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:11,418 - gensim.models.word2vec - INFO\n",
      "Msg: collected 3023 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:11,419 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:11,423 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1097 unique words (36.29% of original 3023, drops 1926)', 'datetime': '2025-06-17T17:14:11.423399', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,424 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5025 word corpus (72.29% of original 6951, drops 1926)', 'datetime': '2025-06-17T17:14:11.424412', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,429 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 3023 items\n",
      "\n",
      "2025-06-17 17:14:11,434 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 49 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,435 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4378.075459906837 word corpus (87.1%% of prior 5025)', 'datetime': '2025-06-17T17:14:11.435518', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,445 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1097 words and 200 dimensions: 2303700 bytes\n",
      "\n",
      "2025-06-17 17:14:11,446 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,449 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.449907', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,451 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1097 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.451326', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,472 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4353 effective words) took 0.0s, 272613 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,489 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4369 effective words) took 0.0s, 284166 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,502 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4381 effective words) took 0.0s, 294299 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,532 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4378 effective words) took 0.0s, 288550 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,550 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4384 effective words) took 0.0s, 302785 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,569 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4391 effective words) took 0.0s, 296239 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,589 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4380 effective words) took 0.0s, 283785 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,606 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4383 effective words) took 0.0s, 278118 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,623 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4356 effective words) took 0.0s, 294257 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,639 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4413 effective words) took 0.0s, 287288 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,639 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (43788 effective words) took 0.2s, 223862 effective words/s', 'datetime': '2025-06-17T17:14:11.639582', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,639 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1097, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:11.639582', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:11,639 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_lemmatized_8.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:11.639582', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:11,650 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:11,654 - gensim.utils - INFO\n",
      "Msg: saved w2v_lemmatized_8.model\n",
      "\n",
      "Kaydedildi: w2v_lemmatized_8.model\n",
      "2025-06-17 17:14:11,656 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:11,656 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:11,656 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:11,656 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:11,662 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:11.662768', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,662 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:11.662768', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,668 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:11,669 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,670 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:11.670745', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,673 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 100 dimensions: 1427400 bytes\n",
      "\n",
      "2025-06-17 17:14:11,673 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,673 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.673846', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,673 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.673846', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,689 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 892559 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,700 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4575 effective words) took 0.0s, 877496 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,710 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4530 effective words) took 0.0s, 906907 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,721 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4549 effective words) took 0.0s, 892451 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,729 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4569 effective words) took 0.0s, 927377 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,739 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4543 effective words) took 0.0s, 896780 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,746 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4557 effective words) took 0.0s, 857772 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,757 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4533 effective words) took 0.0s, 906292 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,767 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4581 effective words) took 0.0s, 947800 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,776 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4567 effective words) took 0.0s, 897743 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,776 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45554 effective words) took 0.1s, 476246 effective words/s', 'datetime': '2025-06-17T17:14:11.776294', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,776 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:11.776294', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:11,776 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_1.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:11.776294', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:11,776 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:11,783 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_1.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_1.model\n",
      "2025-06-17 17:14:11,785 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:11,785 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:11,787 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:11,787 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:11,790 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:11.790655', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,791 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:11.791658', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,796 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:11,796 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,796 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:11.796978', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,805 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 100 dimensions: 1427400 bytes\n",
      "\n",
      "2025-06-17 17:14:11,806 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,806 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.806908', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,806 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.806908', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,820 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 828387 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,829 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4551 effective words) took 0.0s, 913434 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,836 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4565 effective words) took 0.0s, 816432 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,836 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4574 effective words) took 0.0s, 857759 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,852 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4550 effective words) took 0.0s, 880469 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,867 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4569 effective words) took 0.0s, 843565 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,867 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4559 effective words) took 0.0s, 952291 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,884 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4566 effective words) took 0.0s, 813107 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,884 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4569 effective words) took 0.0s, 945689 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4597 effective words) took 0.0s, 848766 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45650 effective words) took 0.1s, 466441 effective words/s', 'datetime': '2025-06-17T17:14:11.907790', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:11.907790', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_2.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:11.907790', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:11,907 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_2.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_2.model\n",
      "2025-06-17 17:14:11,907 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:11,915 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:11,917 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:11,918 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:11,921 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:11.921701', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,923 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:11.923275', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,923 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:11,923 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:11,929 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:11.929412', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,936 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 200 dimensions: 2305800 bytes\n",
      "\n",
      "2025-06-17 17:14:11,937 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:11,939 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:11.939557', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:11,940 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:11.940393', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:11,950 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 747311 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,956 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4575 effective words) took 0.0s, 789460 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,972 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4530 effective words) took 0.0s, 767069 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,985 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4549 effective words) took 0.0s, 794335 effective words/s\n",
      "\n",
      "2025-06-17 17:14:11,993 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4569 effective words) took 0.0s, 714587 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,006 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4543 effective words) took 0.0s, 806555 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,017 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4557 effective words) took 0.0s, 760920 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,029 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4533 effective words) took 0.0s, 760239 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,039 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4581 effective words) took 0.0s, 740065 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,050 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4567 effective words) took 0.0s, 733066 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,051 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45554 effective words) took 0.1s, 413834 effective words/s', 'datetime': '2025-06-17T17:14:12.051773', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,052 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:12.052841', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:12,053 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_3.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:12.053861', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:12,054 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:12,059 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_3.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_3.model\n",
      "2025-06-17 17:14:12,061 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:12,061 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:12,061 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:12,061 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:12,068 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:12.068870', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,069 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:12.069876', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,074 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:12,075 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:12,076 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:12.075208', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,084 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 200 dimensions: 2305800 bytes\n",
      "\n",
      "2025-06-17 17:14:12,085 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:12,087 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:12.087602', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,088 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:12.088617', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,101 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 640899 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,115 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4551 effective words) took 0.0s, 726324 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,128 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4565 effective words) took 0.0s, 481439 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,144 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4574 effective words) took 0.0s, 592173 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,154 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4550 effective words) took 0.0s, 695676 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,165 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4569 effective words) took 0.0s, 657287 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,184 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4559 effective words) took 0.0s, 656737 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,195 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4566 effective words) took 0.0s, 712703 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,207 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4569 effective words) took 0.0s, 769360 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,217 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4597 effective words) took 0.0s, 762241 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,218 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45650 effective words) took 0.1s, 352235 effective words/s', 'datetime': '2025-06-17T17:14:12.218952', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,219 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:12.219965', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:12,220 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_4.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:12.220971', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:12,220 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:12,220 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_4.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_4.model\n",
      "2025-06-17 17:14:12,220 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:12,220 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:12,229 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:12,229 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:12,232 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:12.232409', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,233 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:12.233521', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,237 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:12,238 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:12,238 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:12.238940', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,242 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 100 dimensions: 1427400 bytes\n",
      "\n",
      "2025-06-17 17:14:12,242 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:12,250 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:12.250249', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,250 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:12.250249', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,264 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 411962 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,273 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4575 effective words) took 0.0s, 425419 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,294 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4530 effective words) took 0.0s, 445034 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,306 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4549 effective words) took 0.0s, 421223 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,326 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4569 effective words) took 0.0s, 397405 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,340 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4543 effective words) took 0.0s, 433608 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,364 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4557 effective words) took 0.0s, 338883 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,385 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4533 effective words) took 0.0s, 381203 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,412 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4581 effective words) took 0.0s, 287014 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,430 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4567 effective words) took 0.0s, 349116 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,431 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45554 effective words) took 0.2s, 250471 effective words/s', 'datetime': '2025-06-17T17:14:12.431979', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,434 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:12.434273', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:12,435 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_5.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:12.435377', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:12,437 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:12,442 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_5.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_5.model\n",
      "2025-06-17 17:14:12,445 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:12,447 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:12,451 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:12,452 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:12,459 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:12.459579', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,461 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:12.461583', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,472 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:12,474 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:12,476 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:12.476958', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,484 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 100 dimensions: 1427400 bytes\n",
      "\n",
      "2025-06-17 17:14:12,486 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:12,487 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:12.487283', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,488 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:12.488289', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,504 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 363105 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,521 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4551 effective words) took 0.0s, 363818 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,536 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4565 effective words) took 0.0s, 366793 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,555 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4574 effective words) took 0.0s, 355635 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,574 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4550 effective words) took 0.0s, 345086 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,591 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4569 effective words) took 0.0s, 349946 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,603 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4559 effective words) took 0.0s, 358564 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,626 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4566 effective words) took 0.0s, 338782 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,646 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4569 effective words) took 0.0s, 327091 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,664 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4597 effective words) took 0.0s, 360351 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,665 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45650 effective words) took 0.2s, 257028 effective words/s', 'datetime': '2025-06-17T17:14:12.665862', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,667 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=100, alpha=0.025>', 'datetime': '2025-06-17T17:14:12.667327', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:12,668 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_6.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:12.668348', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:12,668 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_6.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_6.model\n",
      "2025-06-17 17:14:12,670 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:12.670973', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,670 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:12.670973', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,685 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:12,686 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:12,686 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:12.686983', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,691 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 200 dimensions: 2305800 bytes\n",
      "\n",
      "2025-06-17 17:14:12,691 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:12,691 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:12.691121', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,691 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-06-17T17:14:12.691121', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,715 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 363616 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,734 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4575 effective words) took 0.0s, 337850 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,751 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4530 effective words) took 0.0s, 341343 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,770 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4549 effective words) took 0.0s, 330334 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,787 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4569 effective words) took 0.0s, 342209 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,805 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4543 effective words) took 0.0s, 361183 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,822 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4557 effective words) took 0.0s, 341484 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,839 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4533 effective words) took 0.0s, 363332 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,855 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4581 effective words) took 0.0s, 363603 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,874 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4567 effective words) took 0.0s, 337574 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,875 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45554 effective words) took 0.2s, 259042 effective words/s', 'datetime': '2025-06-17T17:14:12.875239', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,876 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:12.876413', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:12,877 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_7.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:12.877434', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:12,877 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:12,877 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_7.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_7.model\n",
      "2025-06-17 17:14:12,884 - gensim.models.word2vec - INFO\n",
      "Msg: collecting all words and their counts\n",
      "\n",
      "2025-06-17 17:14:12,884 - gensim.models.word2vec - INFO\n",
      "Msg: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "\n",
      "2025-06-17 17:14:12,886 - gensim.models.word2vec - INFO\n",
      "Msg: collected 2801 word types from a corpus of 6951 raw words and 800 sentences\n",
      "\n",
      "2025-06-17 17:14:12,887 - gensim.models.word2vec - INFO\n",
      "Msg: Creating a fresh vocabulary\n",
      "\n",
      "2025-06-17 17:14:12,889 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 1098 unique words (39.20% of original 2801, drops 1703)', 'datetime': '2025-06-17T17:14:12.889744', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,890 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5248 word corpus (75.50% of original 6951, drops 1703)', 'datetime': '2025-06-17T17:14:12.890757', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,896 - gensim.models.word2vec - INFO\n",
      "Msg: deleting the raw counts dictionary of 2801 items\n",
      "\n",
      "2025-06-17 17:14:12,896 - gensim.models.word2vec - INFO\n",
      "Msg: sample=0.001 downsamples 56 most-common words\n",
      "\n",
      "2025-06-17 17:14:12,897 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4562.704109860675 word corpus (86.9%% of prior 5248)', 'datetime': '2025-06-17T17:14:12.897176', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,907 - gensim.models.word2vec - INFO\n",
      "Msg: estimated required memory for 1098 words and 200 dimensions: 2305800 bytes\n",
      "\n",
      "2025-06-17 17:14:12,908 - gensim.models.word2vec - INFO\n",
      "Msg: resetting layer weights\n",
      "\n",
      "2025-06-17 17:14:12,909 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-06-17T17:14:12.909341', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "\n",
      "2025-06-17 17:14:12,909 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1098 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2025-06-17T17:14:12.909341', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:12,930 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 0: training on 6951 raw words (4550 effective words) took 0.0s, 289942 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,951 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 1: training on 6951 raw words (4551 effective words) took 0.0s, 290645 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,978 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 2: training on 6951 raw words (4565 effective words) took 0.0s, 252190 effective words/s\n",
      "\n",
      "2025-06-17 17:14:12,989 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 3: training on 6951 raw words (4574 effective words) took 0.0s, 292369 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,023 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 4: training on 6951 raw words (4550 effective words) took 0.0s, 298549 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,042 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 5: training on 6951 raw words (4569 effective words) took 0.0s, 296802 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,056 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 6: training on 6951 raw words (4559 effective words) took 0.0s, 288822 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,079 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 7: training on 6951 raw words (4566 effective words) took 0.0s, 295247 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,104 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 8: training on 6951 raw words (4569 effective words) took 0.0s, 282926 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,127 - gensim.models.word2vec - INFO\n",
      "Msg: EPOCH 9: training on 6951 raw words (4597 effective words) took 0.0s, 288468 effective words/s\n",
      "\n",
      "2025-06-17 17:14:13,128 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'msg': 'training on 69510 raw words (45650 effective words) took 0.2s, 210106 effective words/s', 'datetime': '2025-06-17T17:14:13.128181', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
      "\n",
      "2025-06-17 17:14:13,129 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1098, vector_size=200, alpha=0.025>', 'datetime': '2025-06-17T17:14:13.129192', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "\n",
      "2025-06-17 17:14:13,129 - gensim.utils - INFO\n",
      "Msg: Word2Vec lifecycle event {'fname_or_handle': 'w2v_stemmed_8.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-06-17T17:14:13.129192', 'gensim': '4.3.3', 'python': '3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'saving'}\n",
      "\n",
      "2025-06-17 17:14:13,130 - gensim.utils - INFO\n",
      "Msg: not storing attribute cum_table\n",
      "\n",
      "2025-06-17 17:14:13,134 - gensim.utils - INFO\n",
      "Msg: saved w2v_stemmed_8.model\n",
      "\n",
      "Kaydedildi: w2v_stemmed_8.model\n",
      "\n",
      "Ödev-1 tamamlandı!\n",
      "Oluşturulan dosyalar:\n",
      "- lemmatized.csv\n",
      "- stemmed.csv\n",
      "- tf-idf_lemmatized.pkl\n",
      "- tf-idf_stemmed.pkl\n",
      "- 16 adet Word2Vec modeli (.model dosyaları)\n",
      "\n",
      "Örnek veriler:\n",
      "Lemmatized veri örneği:\n",
      "                                      original_title  \\\n",
      "0  Ünlü markanın oda kokusu piyasadan toplatılıyo...   \n",
      "1                        Yeni ekonomi paketi TBMM'de   \n",
      "2  TBMM'ye sunulan ekonomi paketiyle vergide adal...   \n",
      "3  İsrail-İran gerilimi enflasyon-resesyon ikilem...   \n",
      "4  Bundesbank'tan kara senaryo: Petrol fiyatları ...   \n",
      "\n",
      "                                             content                   source  \\\n",
      "0  ünlü markanın oda kokusu piyasadan toplatılıyo...  Anlatilaninotesi.com.tr   \n",
      "1                        yeni ekonomi paketi tbmm de            Haberturk.com   \n",
      "2  tbmm ye sunulan ekonomi paketiyle vergide adal...           Anadolu Agency   \n",
      "3  i srail i ran gerilimi enflasyon resesyon ikil...           Anadolu Agency   \n",
      "4  bundesbank tan kara senaryo petrol fiyatları ö...             Sabah.com.tr   \n",
      "\n",
      "  category  \n",
      "0  ekonomi  \n",
      "1  ekonomi  \n",
      "2  ekonomi  \n",
      "3  ekonomi  \n",
      "4  ekonomi  \n",
      "\n",
      "Stemmed veri örneği:\n",
      "                                      original_title  \\\n",
      "0  Ünlü markanın oda kokusu piyasadan toplatılıyo...   \n",
      "1                        Yeni ekonomi paketi TBMM'de   \n",
      "2  TBMM'ye sunulan ekonomi paketiyle vergide adal...   \n",
      "3  İsrail-İran gerilimi enflasyon-resesyon ikilem...   \n",
      "4  Bundesbank'tan kara senaryo: Petrol fiyatları ...   \n",
      "\n",
      "                                             content                   source  \\\n",
      "0  ünl marka oda koku piyasa toplatılıyor satış y...  Anlatilaninotesi.com.tr   \n",
      "1                           yen ekonom paket tbmm de            Haberturk.com   \n",
      "2  tbmm ye sunulan ekonom paketiyle vergi adalet ...           Anadolu Agency   \n",
      "3  i srail i ran gerilim enflasyon resesyon ikile...           Anadolu Agency   \n",
      "4  bundesbank tan kara senaryo petrol fiyatlar ön...             Sabah.com.tr   \n",
      "\n",
      "  category  \n",
      "0  ekonomi  \n",
      "1  ekonomi  \n",
      "2  ekonomi  \n",
      "3  ekonomi  \n",
      "4  ekonomi  \n"
     ]
    }
   ],
   "source": [
    "# Ödev-1: Haber Başlığı Veri Toplama ve Ön İşleme\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Türkçe doğal dil işleme için kütüphaneler\n",
    "from zemberek import TurkishSentenceNormalizer, TurkishMorphology, TurkishTokenizer\n",
    "from zemberek import TurkishSentenceExtractor\n",
    "\n",
    "# Gensim ve sklearn kütüphaneleri\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Görselleştirme\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "class NewsDataCollector:\n",
    "    def __init__(self):\n",
    "        # NewsAPI anahtarı - ücretsiz hesap için günlük limit var\n",
    "        self.api_key = \"281597f62eb44872b2b643b1e79d866c\"  # Buraya kendi API anahtarınızı girin\n",
    "        self.base_url = \"https://newsapi.org/v2/everything\"\n",
    "        \n",
    "    def collect_news_data(self, query_terms=None, days_back=30, max_articles=1000):\n",
    "        \"\"\"\n",
    "        Haber verilerini NewsAPI'den toplar\n",
    "        \"\"\"\n",
    "        if query_terms is None:\n",
    "            query_terms = [\"ekonomi\", \"siyaset\", \"spor\", \"teknoloji\", \"sağlık\", \"eğitim\", \"çevre\", \"kültür\"]\n",
    "        \n",
    "        all_articles = []\n",
    "        \n",
    "        # Tarih aralığını belirle\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "        \n",
    "        for query in query_terms:\n",
    "            print(f\"'{query}' konusu için veri toplama...\")\n",
    "            \n",
    "            params = {\n",
    "                'q': query,\n",
    "                'language': 'tr',\n",
    "                'from': start_date.strftime('%Y-%m-%d'),\n",
    "                'to': end_date.strftime('%Y-%m-%d'),\n",
    "                'sortBy': 'publishedAt',\n",
    "                'pageSize': min(100, max_articles // len(query_terms)),\n",
    "                'apiKey': self.api_key\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(self.base_url, params=params)\n",
    "                data = response.json()\n",
    "                \n",
    "                if response.status_code == 200 and 'articles' in data:\n",
    "                    for article in data['articles']:\n",
    "                        if article['title'] and len(article['title'].strip()) > 10:\n",
    "                            all_articles.append({\n",
    "                                'title': article['title'],\n",
    "                                'description': article.get('description', ''),\n",
    "                                'source': article['source']['name'],\n",
    "                                'publishedAt': article['publishedAt'],\n",
    "                                'url': article['url'],\n",
    "                                'category': query\n",
    "                            })\n",
    "                else:\n",
    "                    print(f\"API Hatası: {data.get('message', 'Bilinmeyen hata')}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Hata: {e}\")\n",
    "            \n",
    "            # API rate limit için bekle\n",
    "            time.sleep(1)\n",
    "        \n",
    "        return pd.DataFrame(all_articles)\n",
    "    \n",
    "    def create_sample_data(self, size=1000):\n",
    "        \"\"\"\n",
    "        API anahtarı yoksa örnek veri oluştur\n",
    "        \"\"\"\n",
    "        print(\"Örnek haber başlığı verisi oluşturuluyor...\")\n",
    "        \n",
    "        # Türkçe örnek haber başlıkları\n",
    "        sample_titles = [\n",
    "            \"Ekonomide son gelişmeler ve piyasa analizi\",\n",
    "            \"Teknoloji sektöründe yeni yatırımlar açıklandı\",\n",
    "            \"Sağlık Bakanlığı'ndan önemli açıklama\",\n",
    "            \"Eğitim reformu ile ilgili detaylar belli oldu\",\n",
    "            \"Spor müsabakalarında heyecan dorukta\",\n",
    "            \"Çevre koruma projelerine büyük destek\",\n",
    "            \"Kültür ve sanat etkinlikleri devam ediyor\",\n",
    "            \"Siyasi gelişmeler gündem oluşturuyor\",\n",
    "            \"Ekonomik büyüme rakamları açıklandı\",\n",
    "            \"Teknolojide yapay zeka devrimi\",\n",
    "            \"Sağlık sisteminde dijital dönüşüm\",\n",
    "            \"Eğitimde uzaktan öğretim modeli\",\n",
    "            \"Spor yatırımları artış gösteriyor\",\n",
    "            \"Çevre dostu teknolojiler gelişiyor\",\n",
    "            \"Kültürel miras korunuyor\",\n",
    "            \"Siyasi istikrar ekonomiyi etkiliyor\"\n",
    "        ]\n",
    "        \n",
    "        categories = [\"ekonomi\", \"teknoloji\", \"sağlık\", \"eğitim\", \"spor\", \"çevre\", \"kültür\", \"siyaset\"]\n",
    "        sources = [\"Haber A\", \"Haber B\", \"Haber C\", \"Gazete X\", \"Gazete Y\", \"Portal Z\"]\n",
    "        \n",
    "        # Varyasyonlarla veri oluştur\n",
    "        data = []\n",
    "        for i in range(size):\n",
    "            base_title = np.random.choice(sample_titles)\n",
    "            category = np.random.choice(categories)\n",
    "            source = np.random.choice(sources)\n",
    "            \n",
    "            # Başlığa küçük varyasyonlar ekle\n",
    "            variations = [\n",
    "                base_title,\n",
    "                base_title + \" - Detaylar\",\n",
    "                base_title + \" gündemde\",\n",
    "                base_title + \" konuşuluyor\",\n",
    "                \"Son dakika: \" + base_title,\n",
    "                base_title + \" haberleri\",\n",
    "                base_title + \" açıklaması yapıldı\"\n",
    "            ]\n",
    "            \n",
    "            title = np.random.choice(variations)\n",
    "            \n",
    "            data.append({\n",
    "                'title': title,\n",
    "                'description': f\"{title} ile ilgili detaylı bilgiler...\",\n",
    "                'source': source,\n",
    "                'publishedAt': datetime.now().isoformat(),\n",
    "                'category': category,\n",
    "                'url': f\"https://example.com/haber-{i}\"\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "class TurkishTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.morphology = TurkishMorphology.create_with_defaults()\n",
    "            self.normalizer = TurkishSentenceNormalizer(self.morphology)\n",
    "            print(\"Zemberek başarıyla yüklendi\")\n",
    "        except:\n",
    "            print(\"Zemberek yüklenemedi, alternatif yöntemler kullanılacak\")\n",
    "            self.morphology = None\n",
    "            self.normalizer = None\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Metni temizle ve normalize et\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Küçük harfe çevir\n",
    "        text = text.lower()\n",
    "        \n",
    "        # HTML etiketlerini temizle\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        \n",
    "        # URL'leri temizle\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        \n",
    "        # Email adreslerini temizle\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Sayıları temizle\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Özel karakterleri temizle (Türkçe karakterler hariç)\n",
    "        text = re.sub(r'[^\\w\\s\\u00C0-\\u017F]', ' ', text)\n",
    "        \n",
    "        # Çoklu boşlukları tek boşluğa çevir\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def tokenize_turkish(self, text):\n",
    "        \"\"\"\n",
    "        Türkçe metin için tokenizasyon\n",
    "        \"\"\"\n",
    "        if self.morphology:\n",
    "            try:\n",
    "                results = self.morphology.analyze_sentence(text)\n",
    "                tokens = [result.dictionary_item.lemma for result in results]\n",
    "                return tokens\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Alternatif basit tokenizasyon\n",
    "        return text.split()\n",
    "    \n",
    "    def lemmatize_text(self, text):\n",
    "        \"\"\"\n",
    "        Metni lemmatize et\n",
    "        \"\"\"\n",
    "        if self.morphology:\n",
    "            try:\n",
    "                results = self.morphology.analyze_sentence(text)\n",
    "                lemmatized = [result.dictionary_item.lemma for result in results]\n",
    "                return ' '.join(lemmatized)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Alternatif: sadece temizlenmiş metin döndür\n",
    "        return self.clean_text(text)\n",
    "    \n",
    "    def stem_text(self, text):\n",
    "        \"\"\"\n",
    "        Basit stemming (Türkçe için yaklaşık)\n",
    "        \"\"\"\n",
    "        # Türkçe için basit stemming kuralları\n",
    "        common_suffixes = [\n",
    "            'lar', 'ler', 'da', 'de', 'ta', 'te', 'dan', 'den', 'tan', 'ten',\n",
    "            'in', 'ın', 'un', 'ün', 'nin', 'nın', 'nun', 'nün',\n",
    "            'i', 'ı', 'u', 'ü', 'si', 'sı', 'su', 'sü'\n",
    "        ]\n",
    "        \n",
    "        words = text.split()\n",
    "        stemmed_words = []\n",
    "        \n",
    "        for word in words:\n",
    "            if len(word) > 3:\n",
    "                for suffix in sorted(common_suffixes, key=len, reverse=True):\n",
    "                    if word.endswith(suffix) and len(word) - len(suffix) > 2:\n",
    "                        word = word[:-len(suffix)]\n",
    "                        break\n",
    "            stemmed_words.append(word)\n",
    "        \n",
    "        return ' '.join(stemmed_words)\n",
    "\n",
    "def main():\n",
    "    print(\"Haber Başlığı Çoğaltma Tespiti - Ödev 1\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Veri Toplama\n",
    "    collector = NewsDataCollector()\n",
    "    \n",
    "    # Gerçek API anahtarı varsa NewsAPI'den, yoksa örnek veri\n",
    "    try:\n",
    "        df = collector.collect_news_data(max_articles=1000)\n",
    "        if df.empty:\n",
    "            print(\"API'den veri alınamadı, örnek veri oluşturuluyor...\")\n",
    "            df = collector.create_sample_data(1000)\n",
    "    except:\n",
    "        print(\"Örnek veri oluşturuluyor...\")\n",
    "        df = collector.create_sample_data(1000)\n",
    "    \n",
    "    print(f\"Toplam {len(df)} haber başlığı toplandı\")\n",
    "    \n",
    "    # 2. Veri Analizi\n",
    "    print(\"\\nVeri Seti Analizi:\")\n",
    "    print(f\"- Toplam kayıt: {len(df)}\")\n",
    "    print(f\"- Benzersiz başlık: {df['title'].nunique()}\")\n",
    "    print(f\"- Kaynak sayısı: {df['source'].nunique()}\")\n",
    "    \n",
    "    # 3. Metin Ön İşleme\n",
    "    preprocessor = TurkishTextPreprocessor()\n",
    "    \n",
    "    print(\"\\nMetin ön işleme başlıyor...\")\n",
    "    \n",
    "    # Temizleme\n",
    "    df['title_clean'] = df['title'].apply(preprocessor.clean_text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    df['title_lemmatized'] = df['title_clean'].apply(preprocessor.lemmatize_text)\n",
    "    \n",
    "    # Stemming\n",
    "    df['title_stemmed'] = df['title_clean'].apply(preprocessor.stem_text)\n",
    "    \n",
    "    # Boş kayıtları temizle\n",
    "    df = df[df['title_clean'].str.len() > 0]\n",
    "    df = df[df['title_lemmatized'].str.len() > 0]\n",
    "    df = df[df['title_stemmed'].str.len() > 0]\n",
    "    \n",
    "    print(f\"Temizleme sonrası kayıt sayısı: {len(df)}\")\n",
    "    \n",
    "    # 4. Temizlenmiş veri setlerini kaydet\n",
    "    lemmatized_df = df[['title', 'title_lemmatized', 'source', 'category']].copy()\n",
    "    lemmatized_df.columns = ['original_title', 'content', 'source', 'category']\n",
    "    lemmatized_df.to_csv('lemmatized.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    stemmed_df = df[['title', 'title_stemmed', 'source', 'category']].copy()\n",
    "    stemmed_df.columns = ['original_title', 'content', 'source', 'category']\n",
    "    stemmed_df.to_csv('stemmed.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"Temizlenmiş veri setleri kaydedildi:\")\n",
    "    print(\"- lemmatized.csv\")\n",
    "    print(\"- stemmed.csv\")\n",
    "    \n",
    "    # 5. TF-IDF Modelleri\n",
    "    print(\"\\nTF-IDF modelleri oluşturuluyor...\")\n",
    "    \n",
    "    # Lemmatized için TF-IDF\n",
    "    tfidf_lem = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        min_df=2,\n",
    "        max_df=0.8,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=None  # Türkçe stop words listesi eklenebilir\n",
    "    )\n",
    "    \n",
    "    tfidf_lem_matrix = tfidf_lem.fit_transform(lemmatized_df['content'])\n",
    "    \n",
    "    # Stemmed için TF-IDF\n",
    "    tfidf_stem = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        min_df=2,\n",
    "        max_df=0.8,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=None\n",
    "    )\n",
    "    \n",
    "    tfidf_stem_matrix = tfidf_stem.fit_transform(stemmed_df['content'])\n",
    "    \n",
    "    # TF-IDF modellerini kaydet\n",
    "    with open('tf-idf_lemmatized.pkl', 'wb') as f:\n",
    "        pickle.dump({'model': tfidf_lem, 'matrix': tfidf_lem_matrix}, f)\n",
    "    \n",
    "    with open('tf-idf_stemmed.pkl', 'wb') as f:\n",
    "        pickle.dump({'model': tfidf_stem, 'matrix': tfidf_stem_matrix}, f)\n",
    "    \n",
    "    print(\"TF-IDF modelleri kaydedildi\")\n",
    "    \n",
    "    # 6. Word2Vec Modelleri\n",
    "    print(\"\\nWord2Vec modelleri oluşturuluyor...\")\n",
    "    \n",
    "    # Lemmatized için tokenlar\n",
    "    lem_tokens = [text.split() for text in lemmatized_df['content']]\n",
    "    \n",
    "    # Stemmed için tokenlar\n",
    "    stem_tokens = [text.split() for text in stemmed_df['content']]\n",
    "    \n",
    "    # Word2Vec parametreleri\n",
    "    w2v_params = [\n",
    "        {'vector_size': 100, 'window': 5, 'sg': 0},  # CBOW, 100d, window=5\n",
    "        {'vector_size': 100, 'window': 10, 'sg': 0}, # CBOW, 100d, window=10\n",
    "        {'vector_size': 200, 'window': 5, 'sg': 0},  # CBOW, 200d, window=5\n",
    "        {'vector_size': 200, 'window': 10, 'sg': 0}, # CBOW, 200d, window=10\n",
    "        {'vector_size': 100, 'window': 5, 'sg': 1},  # Skip-gram, 100d, window=5\n",
    "        {'vector_size': 100, 'window': 10, 'sg': 1}, # Skip-gram, 100d, window=10\n",
    "        {'vector_size': 200, 'window': 5, 'sg': 1},  # Skip-gram, 200d, window=5\n",
    "        {'vector_size': 200, 'window': 10, 'sg': 1}  # Skip-gram, 200d, window=10\n",
    "    ]\n",
    "    \n",
    "    # Lemmatized Word2Vec modelleri\n",
    "    for i, params in enumerate(w2v_params):\n",
    "        model = Word2Vec(\n",
    "            sentences=lem_tokens,\n",
    "            vector_size=params['vector_size'],\n",
    "            window=params['window'],\n",
    "            min_count=2,\n",
    "            workers=4,\n",
    "            sg=params['sg'],\n",
    "            epochs=10\n",
    "        )\n",
    "        \n",
    "        model_name = f\"w2v_lemmatized_{i+1}\"\n",
    "        model.save(f\"{model_name}.model\")\n",
    "        print(f\"Kaydedildi: {model_name}.model\")\n",
    "    \n",
    "    # Stemmed Word2Vec modelleri\n",
    "    for i, params in enumerate(w2v_params):\n",
    "        model = Word2Vec(\n",
    "            sentences=stem_tokens,\n",
    "            vector_size=params['vector_size'],\n",
    "            window=params['window'],\n",
    "            min_count=2,\n",
    "            workers=4,\n",
    "            sg=params['sg'],\n",
    "            epochs=10\n",
    "        )\n",
    "        \n",
    "        model_name = f\"w2v_stemmed_{i+1}\"\n",
    "        model.save(f\"{model_name}.model\")\n",
    "        print(f\"Kaydedildi: {model_name}.model\")\n",
    "    \n",
    "    print(\"\\nÖdev-1 tamamlandı!\")\n",
    "    print(\"Oluşturulan dosyalar:\")\n",
    "    print(\"- lemmatized.csv\")\n",
    "    print(\"- stemmed.csv\")\n",
    "    print(\"- tf-idf_lemmatized.pkl\")\n",
    "    print(\"- tf-idf_stemmed.pkl\")\n",
    "    print(\"- 16 adet Word2Vec modeli (.model dosyaları)\")\n",
    "    \n",
    "    # Örnek veri gösterimi\n",
    "    print(\"\\nÖrnek veriler:\")\n",
    "    print(\"Lemmatized veri örneği:\")\n",
    "    print(lemmatized_df.head())\n",
    "    print(\"\\nStemmed veri örneği:\")\n",
    "    print(stemmed_df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c794449-3ba7-4ba1-95ee-b7ba897ffba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
